[toc]

RedisCluster自身实现了高可用，不需要额外配置Redis-Sentinel。高可用首先要解决集群部分失效的场景。当集群内少量节点出现故障时，通过自动故障转移保证集群内可以正常对外提供服务。



## 故障发现

**当集群中某个节点出现问题时，需要通过一种健壮的方式保证识别节点是否发生了故障**。Redis集群内通过ping/pong消息实现节点通讯。消息不但可以传播节点槽信息，还可以传播其他状态如：主从状态，节点故障等。

**因此故障发现也是通过消息传播机制（基于Goosip协议）实现的，其主要环节包括**：

- 主观下线（Probably Fail）：指某一个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判断，只能代表一个节点的意见，可能存在误判情况
- 客观下线（Fail）：指标记一个节点真正的下线，集群内多个节点都认为这个节点不可用，从而达成共识的结果。如果是持有槽的主节点发生故障，需要为该节点进行故障转移。



## 主观下线



集群中每个节点会定期向其他节点发送ping信息，接收节点回复pong消息作为响应。**如果在cluster-node-timeout时间内通信一直失败，则发送节点会认为接收节点存在故障**，此时把接收节点标记为主观下线（Probably Fail）

具体流程如下：

- 节点a发送ping消息给节点b，如果通信正常将接收到pong消息，节点a更新最近一次与节点b的通信时间
- 如果节点a与节点b通信出现问题则断开连接，下次会进行重连。如果一直通信失败，则节点a记录的与节点b最后通信时间将无法更新
- 节点a内的定时任务检测到与节点b最后通信时间超过cluster-nodetimeout时，更新本地对节点b的状态为主观下线（pfail）

![image-20210319161619077](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210319161619077.png)



主观下线简单来讲就是，**当cluster-note-timeout时间内某节点无法与另一个节点顺利完成ping消息通信时，则将该节点标记为主观下线状态**。每个节点内的cluster State结构都需要保存其他节点信息，用于从自身视角判断其他节点的状态。结构关键属性如下：

```c
typedef struct clusterState {
    clusterNode *myself; /* 自身节点 /
    dict *nodes;/* 当前集群内所有节点的字典集合，key为节点ID，value为对应节点ClusterNode结构 */
    ...
} clusterState;字典nodes属性中的clusterNode结构保存了节点的状态,关键属性如下:
 
typedef struct clusterNode {
    int flags; /* 当前节点状态,如:主从角色，是否下线等 */
    mstime_t ping_sent; /* 最后一次与该节点发送ping消息的时间 */
    mstime_t pong_received; /* 最后一次接收到该节点pong消息的时间 */
    ...
} clusterNode;
 
//其中最重要的属性是flags，用于标示该节点对应状态，取值范围如下：
CLUSTER_NODE_MASTER 1 /* 当前为主节点 */
CLUSTER_NODE_SLAVE 2 /* 当前为从节点 */
CLUSTER_NODE_PFAIL 4 /* 主观下线状态 */
CLUSTER_NODE_FAIL 8 /* 客观下线状态 */
CLUSTER_NODE_MYSELF 16 /* 表示自身节点 */
CLUSTER_NODE_HANDSHAKE 32 /* 握手状态，未与其他节点进行消息通信 */
CLUSTER_NODE_NOADDR 64 /* 无地址节点，用于第一次meet通信未完成或者通信失败 */
CLUSTER_NODE_MEET 128 /* 需要接受meet消息的节点状态 */
CLUSTER_NODE_MIGRATE_TO 256 /* 该节点被选中为新的主节点状态 */
```

**Redis集群对于节点最终是否故障的判断非常严谨，只有一个节点认为主观下线并不能准确判断是否故障**，如下图 

![image-20210319163749644](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210319163749644.png)

**因此对于一个健壮的故障发现机制，需要集群内大多数节点都判断6385故障时， 才能认为6385确实发生故障，**然后为6385节点进行故障转移。而这种**多个节点协作完成故障发现的过程叫做客观下线**

## 客观下线

**当某个节点判断另一个节点主观下线后，相应的节点状态会跟随消息在集群内传播**ping/pong消息的消息体会携带集群1/10的其他节点状态数据，当接收节点发现消息体中含有主观下线的节点状态时，会在本地找到故障节点的ClusterNode结构，保存到下线报告链表中。

```c
struct clusterNode { /* 认为是主观下线的clusterNode结构 */
    list *fail_reports; /* 记录了所有其他节点对该节点的下线报告 */
    ...
};
```

通过goosip消息传播，集群内节点不断收集故障节点的下线报告。**当半数以上持有槽的主节点都标记某个节点是主观下线时。触发客观下线流程**，这里有两个问题

- **为什么必须是负责槽的主节点参与故障发现决策？**

  ​	因为集群模式下只有处理槽的主节点才负责读写请求和集群槽等关键信息维护，而从节点只 进行主节点数据和状态信息的复制

- **为什么半数以上处理槽的主节点？**

  ​	必须半数以上是为了应对网络分区等原因造成的集群分割情况，被分割的小集群因为无法完成从主观下线到 客观下线这一关键过程，从而防止小集群完成故障转移之后继续对外提供服务



假设节点a标记节点b主观下线，一段时间后节点a通过消息把节点b的状态发送到其他节点，当节点c接收到消息并解析出消息体含有节点b的pfail状态，会触发客观下线的流程。

1. 当消息体内含有其他节点的pfail状态会判断发送节点的状态，**如果发送节点是主节点则对报告的pfail状态处理，从节点则忽略**

2. 找到pfail对应的节点结构，更新clusterNode内部下线报告链表

3. 根据更新后的下线报告链表尝试进行客观下线

   ![image-20210320185859114](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210320185859114.png)

### 下线报告链表

每个节点ClusterNode结构中都会存在一个下线链表结构，保存了其他主节点针对当前节点的下线报告：

```c
typedef struct clusterNodeFailReport {
    struct clusterNode *node; /* 报告该节点为主观下线的节点 */
    mstime_t time; /* 最近收到下线报告的时间 */
} clusterNodeFailReport;
```

![image-20210318223409272](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210318223409272.png)





- **下线报告中保存了报告故障的节点结构和最近收到下线报告的时间，当接收到fail状态时，**会维护对应节点的下线上报链表
- **每个下线报告都存在有效期：**每次在尝试触发客观下线时，都会检测下线报告是否过期，对于过期的下线报告将被删除。如果在cluster-node-time*2 的时间内该下线报告没有得到更新则过期并删除
- 下线报告的有效期限是server.cluster_node_timeout*2，**主要是针对故障误报的情况**
- 如果在cluster-node-time*2时间内无法收集到一半以上槽节点的下线报告，那么之前的下线报告将会过期，也就是说主观下线上报的速度追赶不上下线报告过期的速度，那么故障节点将永远无法被标记为客观下线从而导致故障转移失败。因此不建议将cluster-node-time设置得过小



**广播fail消息是客观下线的最后一步，它承担着非常重要的职责：**

- 通知集群内所有的节点标记故障节点为客观下线的状态并立刻生效
- 通知故障节点的从节点触发故障转移流程



需要注意的是，尽管存在广播fail消息机制，但是集群所有节点知道故障节点进入客观下线状态是不确定的。比如当出现网络分区时有可能集群被分割为一大一小两个独立集群中。大的集群持有半数槽节点可以完成客观下线并广播fail消息，但是小集群无法接收到fail消息，这个叫做**集群分割**，如下图所示：

![image-20210323182255295](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210323182255295.png)

但是当网络恢复后，只要故障节点变为客观下线，最终总会通过goosip消息传播至集群的所有节点



网络分区会导致分割后的小集群无法收到大集群的fail消息，因此如果故障节点所有的从节点都在小集群内将导致无法完成后续故障转移，**因此部署主从结构时需要根据自身机房/机架拓扑结构，降低主从被分区的可能性**



## 故障恢复



故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它的从节点中选举一个来替换它，从而保证集群的高可用。**下线节点的所有从节点承担故障恢复的义务**，当从节点通过内部定时任务发现自身复制的主节点进入客观下线时，将会触发故障恢复机制

![image-20210323235116367](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210323235116367.png)



### 资格检测

每个从节点都要检测最后与主节点断线时间，判断是否有资格替换故障的主节点

如果从节点与主节点断线时间**超过cluster-node-time\*cluster-slavevalidity-factor**， **则当前从节点不具备故障转移资格**。参数 cluster-slavevalidity-factor 用于从节点的有效因子，默认为10



### 准备选举时间

当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该时间后才能执行后续流程。故障选举时间相关字段如下

```c
struct clusterState {
    ...
    mstime_t failover_auth_time; /* 记录之前或者下次将要执行故障选举时间 */
    int failover_auth_rank;      /* 记录当前从节点排名 */
}
```

**Reids集群中采用延迟触发机制来进行选举**，主要是通过对多个从节点使用不同的延迟时间来支持优先级问题。**复制偏移量越大说明从节点延迟越低，那么它应该具有更高的优先级来代替故障的主节点**

优先级的计算伪代码如下

```c
def clusterGetSlaveRank():
    int rank = 0;
    // 获取从节点的主节点
    ClusteRNode master = myself.slaveof;
    // 获取当前从节点复制偏移量
    long myoffset = replicationGetSlaveOffset();
    // 跟其他从节点复制偏移量对比
    for (int j = 0; j < master.slaves.length; j++):
        // rank表示当前从节点在所有从节点的复制偏移量排名，为0表示偏移量最大.
        if (master.slaves[j] != myself && master.slaves[j].repl_offset > myoffset):
            rank++;
    return rank;
```

根据计算出的优先级排名，更新选举触发时间

```c
def updateFailoverTime():
    // 默认触发选举时间：发现客观下线后一秒内执行。
    server.cluster.failover_auth_time = now() + 500 + random() % 500;
    // 获取当前从节点排名
    int rank = clusterGetSlaveRank();
    long added_delay = rank * 1000;
    // 使用added_delay时间累加到failover_auth_time中
    server.cluster.failover_auth_time += added_delay;
    // 更新当前从节点排名
    server.cluster.failover_auth_rank = rank;
```

![image-20210325142008581](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210325142008581.png)



你主节点b进入客观下线后，其三个从节点根据自身复制偏移量设置延迟选举时间，如复制偏移量最大的slaveb-1，延迟一秒执行，保证复制延迟低的从节点优先发起选举



### 发起选举

当从节点定时任务检测到到达故障选举时间（failover_auth_time）到达后，发起选举流程如下：

- 更新配置纪元
- 广播选举消息

#### 更新配置纪元

​	**配置纪元是一个只增不减的整数**

- 每个主节点自身维护一个配置纪元（clusterNode.configEpoch）标示当前主节点的版本，所有主节点的配置纪元都不相等，从节点会复制主节点的配置纪元
- 整个集群又维护一个全局的配置纪元（clusterState.currentEpoch），用于记录集群内所有主节点配置纪元的最大版本



**执行cluster info命令可以查看到配置纪元信息**

```shell
127.0.0.1:6379> cluster info
...
cluster_current_epoch:15 // 整个集群最大配置纪元
cluster_my_epoch:13      // 当前主节点配置纪元
```

配置纪元会随着ping/pong 消息在集群内传播，当发送方与接收方都是主节点且配置纪元相等时，代表出现了冲突，nodeId更大的一方会递增全局配置纪元并赋值给当前节点来区分冲突



**配置纪元的重要作用**

- 标示集群内每个主节点的不同版本和当前集群内的最大版本
- 每次集群发生重要事件时，这里的重要事件是指出现新的节点（新加入节点或由从节点转换而来），从节点竞争选举。都会递增集群全局的配置纪元并赋值给相关主节点，用于记录这一关键事件
- 主节点具有更大的配置纪元代表了更（第四声）新的集群状态，因此当前节点间进行ping/pong消息交换时，如出现slot等关键信息不一致时，以配置纪元更大的一方为准，防止过时的消息状态污染集群

**配置纪元的应用场景有**

- 新节点加入
- 槽节点映射冲突检测
- 从节点投票选举冲突检测

之前在通过cluster setslot命令修改槽节点映射时，**需要确保执行请求的主节点本地配置纪元（configEpoch）是最大值**，否则修改后的槽信息在消息 传播中不会被拥有更高的配置纪元的节点采纳。由于Gossip通信机制无法准 确知道当前最大的配置纪元在哪个节点，因此在槽迁移任务最后的cluster setslot {slot} node {nodeId}命令需要在全部主节点中执行一遍



**从节点每次发起投票时都会自增集群的全局配置纪元**，并单独保存在 clusterState.failover_auth_epoch 变量中用于标识本次从节点发起选举的版本



#### 广播选举消息

在集群内广播选举消息 **FAILOVER_AUTH_REQUEST**， 并记录已发送过消息的状态，保证该从节点在一个配置纪元内只进行一次选举，消息内容如同ping消息，只是将type类型变为 **FAILOVER_AUTH_REQUEST**



### 选举投票

- **只有持有槽的主节点才会处理故障选举消息**， 因为每个持有槽的节点在一个配置纪元内都有唯一的一张选票，当接到第一个请求投票的从节点消息时回复 **FAILOVER_AUTH_ACK**消息作为投票，之后相同配置纪元内其他从节点的选举消息将忽略

- **投票过程其实是一个领导者选举的过程，**如集群内有N个持有槽的主节点代表有N张选票。由于在每个配置纪元内持有槽的主节点只能投票给一个 从节点，因此只能有一个从节点获得N/2+1的选票，保证能够找出唯一的从节点

- **Redis集群没有直接使用从节点进行领导者选举，**主要因为从节点数必须大于等于3个才能保证凑够N/2+1个节点，将导致从节点资源浪费。使用 集群内所有持有槽的主节点进行领导者选举，即使只有一个从节点也可以完 成选举过程
- **当从节点收集到N/2+1个持有槽的主节点投票时，从节点可以执行替换主节点操作**，例如集群内有5个持有槽的主节点，主节点b故障后还有4个， 当其中一个从节点收集到3张投票时代表获得了足够的选票可以进行替换主 节点操作，如下图所示

![image-20210326005717106](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210326005717106.png)



**运维提示**： 故障主节点也算在投票数内，假设集群内节点规模是3主3从，其中有2 个主节点部署在一台机器上，当这台机器宕机时，由于从节点无法收集到3/2+1个主节点选票将导致故障转移失败。这个问题也适用于故障发现环 节。**因此部署集群时所有主节点最少需要部署在3台物理机上才能避免单点问题**



每个配置纪元代表了一次选举周期，如果在开始投票之后的cluster-node-timeout*2时间内从节点没有获取足够数量的投票，则本次选举作废。从节点对配置纪元自增并发起下一轮投票，直到选举成功为止



### 替换主节点

当从节点收集到足够的选票之后，触发替换主节点操作

- 当前从节点取消复制，变为主节点
- 执行clusterDelSlot操作，撤销故障主节点负责的槽，并执行clusterAddSlot把这些槽委派给自己
- 向集群中广播自己的pong信息，通知集群中所有的节点当前从节点变为主节点并接管了故障节点的槽信息



## 故障转移时间

在介绍完故障发现和恢复的流程后，这时我们可以估算出故障转移时间：

- 1）主观下线（pfail）识别时间=cluster-node-timeout
- 2）主观下线状态消息传播时间<=cluster-node-timeout/2。消息通信机制 对超过cluster-node-timeout/2未通信节点会发起ping消息，消息体在选择包含 哪些节点时会优先选取下线状态节点，所以通常这段时间内能够收集到半数 以上主节点的pfail报告从而完成故障发现
- 3）从节点转移时间<=1000毫秒。由于存在延迟发起选举机制，偏移量最大的从节点会最多延迟1秒发起选举。通常第一次选举就会成功，所以从 节点执行转移时间在1秒以内



![image-20210326010635033](https://gitee.com/Vanni/pic-bed/raw/master/img/image-20210326010635033.png)

因此，**故障转移时间跟cluster-node-timeout参数息息相关，默认15秒**。 配置时可以根据业务容忍度做出适当调整，但不是越小越好



## 参考文献

https://blog.csdn.net/qq_41453285/article/details/103402727

https://dongshao.blog.csdn.net/article/details/106464512

https://dongshao.blog.csdn.net/article/details/106481966

